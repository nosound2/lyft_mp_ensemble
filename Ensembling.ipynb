{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import l5kit\n",
    "import numpy as np\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from l5kit.evaluation import write_pred_csv, read_pred_csv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "batch_size = 64\n",
    "N = 71122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembleTorch(outputs, weights, confidences):\n",
    "    \n",
    "    # all matrices: n,sc,bs,sc2,tl,2\n",
    "    \n",
    "    sc2 = 3\n",
    "    n,bs,sc,tl,_ = outputs.shape\n",
    "    assert (n,bs,sc) == confidences.shape\n",
    "    assert n == len(weights)\n",
    "    \n",
    "    xij = outputs.clone().transpose(1,2)[:,:,:,None,:,:]\n",
    "    x = outputs[0,:,:sc2].clone()\n",
    "    cf = confidences.clone().transpose(1,2)\n",
    "    cf = (weights[:,None,None] * cf)[:,:,:,None,None,None]\n",
    "    \n",
    "    ck = confidences[0,:,:sc2].clone()\n",
    "    if sc != sc2:\n",
    "        ck = ck / ck.sum(1,keepdims=True)\n",
    "    \n",
    "    for m in range(20):\n",
    "        any_update = False\n",
    "        # one trajectory at a time, for convergence purposes\n",
    "        for s in range(sc2):\n",
    "            dist = ((x[None,None,:,:,:,:] - xij)**2).sum(5,keepdims=True)\n",
    "            log_ck = torch.log(ck[None,None,:,:,None,None])\n",
    "            eij = log_ck - 0.5*dist.sum(4,keepdims=True)\n",
    "            values,_ = eij.max(3,keepdims=True)\n",
    "            eij = torch.exp(eij - values)\n",
    "            sum_eij = eij.sum(3,keepdims=True)\n",
    "\n",
    "            mij = cf*eij/sum_eij\n",
    "\n",
    "            x_new = (mij*xij).sum((0,1))/torch.clamp(mij.sum((0,1)),1e-9)\n",
    "            change = (x[:,s] - x_new[:,s]).abs().max()\n",
    "            assert not torch.isnan(change)\n",
    "            if change > 1e-3:\n",
    "                x[:,s] = x_new[:,s]\n",
    "                any_update = True\n",
    "            del dist,eij,values,sum_eij,mij,x_new,change,log_ck\n",
    "        \n",
    "        # repeat the same for confidences\n",
    "        dist = ((x[None,None,:,:,:,:] - xij)**2).sum(5,keepdims=True)\n",
    "        log_ck = torch.log(ck[None,None,:,:,None,None])\n",
    "        eij = log_ck - 0.5*dist.sum(4,keepdims=True)\n",
    "        values,_ = eij.max(3,keepdims=True)\n",
    "        eij = torch.exp(eij - values)\n",
    "        sum_eij = eij.sum(3,keepdims=True)\n",
    "\n",
    "        mij = cf*eij/sum_eij\n",
    "\n",
    "        ck_new = mij.sum((0,1)).squeeze(dim=3).squeeze(dim=2)\n",
    "        ck_new = ck_new / ck_new.sum(1,keepdims=True)\n",
    "        change = (ck - ck_new).abs().max()\n",
    "        assert not ((m > 10) and (change > 1))\n",
    "        assert not torch.isnan(change)\n",
    "        if change > 1e-4:\n",
    "            ck = ck_new\n",
    "            any_update = True\n",
    "        del dist,eij,values,sum_eij,mij,ck_new,change,log_ck\n",
    "        \n",
    "        if not any_update:\n",
    "            break\n",
    "    \n",
    "    del xij,cf\n",
    "    \n",
    "    return x,ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def run_ensemble(names, weights):\n",
    "\n",
    "    st = time.time()\n",
    "    weights /= weights.sum()\n",
    "    weights = weights.cuda()\n",
    "    \n",
    "    pred_coords_list = []\n",
    "    confidences_list = []\n",
    "    timestamps_list = []\n",
    "    track_id_list = []\n",
    "    files = zip(*[read_pred_csv(name) for name in names])\n",
    "\n",
    "    collected = 0\n",
    "    for i,z in tqdm(enumerate(files), total=N):\n",
    "        if collected == 0:\n",
    "            coords = []\n",
    "            confs = []\n",
    "\n",
    "        coords.append(torch.stack([torch.tensor(row['coords']) for row in z], dim=0))\n",
    "        confs.append(torch.stack([torch.tensor(row['conf']) for row in z]))\n",
    "        timestamps_list.append(z[0][\"timestamp\"])\n",
    "        track_id_list.append(z[0][\"track_id\"])\n",
    "        collected += 1\n",
    "\n",
    "        def batch_processing(coords, confs):\n",
    "            coords = torch.stack(coords, dim=1)\n",
    "            confs = torch.stack(confs, dim=1)\n",
    "            x, ck = ensembleTorch(coords.cuda(), weights, confs.cuda())\n",
    "            pred_coords_list.append(x.cpu().detach().numpy())\n",
    "            confidences_list.append(ck.cpu().detach().numpy())\n",
    "\n",
    "        if (collected == batch_size) or (i == (N-1)):\n",
    "            batch_processing(coords, confs)\n",
    "            collected = 0\n",
    "\n",
    "    coords = np.concatenate(pred_coords_list)\n",
    "    confs = np.concatenate(confidences_list)\n",
    "    timestamps = np.array(timestamps_list)\n",
    "    track_ids = np.array(track_id_list)\n",
    "\n",
    "    print('running time:', time.time() - st)\n",
    "\n",
    "    st = time.time()\n",
    "    write_pred_csv(\n",
    "        \"submission.csv\",\n",
    "        timestamps=timestamps,\n",
    "        track_ids=track_ids,\n",
    "        coords=coords, \n",
    "        confs=confs)\n",
    "    print('write csv time:', time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['submission12285.csv','submission12301.csv','submission12976.csv']\n",
    "weights = torch.tensor([0.4,0.3,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['submission_B3.csv','submission_B5.csv','submission_B6_1.csv','submission_B6_2.csv']\n",
    "weights = torch.tensor([0.4,0.25,0.25,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650e0b55a9874adc81f2a48073e0226a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=71122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "running time: 221.61924505233765\n",
      "write csv time: 35.55594205856323\n"
     ]
    }
   ],
   "source": [
    "run_ensemble(names, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
